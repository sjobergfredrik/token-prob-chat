{"ast":null,"code":"import axios from 'axios';\nconst API_KEY = process.env.REACT_APP_OPENAI_API_KEY;\nconst API_URL = 'https://api.openai.com/v1/chat/completions';\n\n/**\n * Sends a prompt to OpenAI API and retrieves the response with token probabilities\n * @param {string} prompt - The user's input prompt\n * @param {number} maxTokens - Maximum number of tokens to generate\n * @param {number} temperature - Controls randomness (0-1)\n * @param {number} logprobs - Number of most likely tokens to return\n * @returns {Promise} - The API response\n */\nexport const getCompletion = async (prompt, maxTokens = 50, temperature = 0.7, logprobs = 5) => {\n  try {\n    const response = await axios.post(API_URL, {\n      model: \"gpt-3.5-turbo\",\n      messages: [{\n        role: \"user\",\n        content: prompt\n      }],\n      max_tokens: maxTokens,\n      temperature,\n      logprobs,\n      stream: false\n    }, {\n      headers: {\n        'Content-Type': 'application/json',\n        'Authorization': `Bearer ${API_KEY}`\n      }\n    });\n\n    // For chat completions, we need to extract the message content\n    const text = response.data.choices[0].message.content;\n\n    // Since chat completions don't provide logprobs directly, we'll simulate them for now\n    // This is a temporary solution until we implement a proper token probability calculation\n    const tokens = text.split(/(\\s+|[.,!?])/g).filter(token => token.trim());\n    const simulatedLogProbs = tokens.map(() => Math.log(0.8)); // Simulating 80% confidence\n\n    return {\n      choices: [{\n        text,\n        logprobs: {\n          tokens,\n          token_logprobs: simulatedLogProbs,\n          top_logprobs: tokens.map(() => ({\n            [tokens[0]]: Math.log(0.8),\n            \"alternative1\": Math.log(0.1),\n            \"alternative2\": Math.log(0.05),\n            \"alternative3\": Math.log(0.05)\n          }))\n        }\n      }]\n    };\n  } catch (error) {\n    var _error$response;\n    console.error('Error calling OpenAI API:', ((_error$response = error.response) === null || _error$response === void 0 ? void 0 : _error$response.data) || error.message);\n    throw error;\n  }\n};","map":{"version":3,"names":["axios","API_KEY","process","env","REACT_APP_OPENAI_API_KEY","API_URL","getCompletion","prompt","maxTokens","temperature","logprobs","response","post","model","messages","role","content","max_tokens","stream","headers","text","data","choices","message","tokens","split","filter","token","trim","simulatedLogProbs","map","Math","log","token_logprobs","top_logprobs","error","_error$response","console"],"sources":["/Users/sjobergf/Documents/chatProbs/token-prob-chat/src/services/openaiService.js"],"sourcesContent":["import axios from 'axios';\n\nconst API_KEY = process.env.REACT_APP_OPENAI_API_KEY;\nconst API_URL = 'https://api.openai.com/v1/chat/completions';\n\n/**\n * Sends a prompt to OpenAI API and retrieves the response with token probabilities\n * @param {string} prompt - The user's input prompt\n * @param {number} maxTokens - Maximum number of tokens to generate\n * @param {number} temperature - Controls randomness (0-1)\n * @param {number} logprobs - Number of most likely tokens to return\n * @returns {Promise} - The API response\n */\nexport const getCompletion = async (prompt, maxTokens = 50, temperature = 0.7, logprobs = 5) => {\n  try {\n    const response = await axios.post(\n      API_URL,\n      {\n        model: \"gpt-3.5-turbo\",\n        messages: [\n          {\n            role: \"user\",\n            content: prompt\n          }\n        ],\n        max_tokens: maxTokens,\n        temperature,\n        logprobs,\n        stream: false\n      },\n      {\n        headers: {\n          'Content-Type': 'application/json',\n          'Authorization': `Bearer ${API_KEY}`\n        }\n      }\n    );\n    \n    // For chat completions, we need to extract the message content\n    const text = response.data.choices[0].message.content;\n    \n    // Since chat completions don't provide logprobs directly, we'll simulate them for now\n    // This is a temporary solution until we implement a proper token probability calculation\n    const tokens = text.split(/(\\s+|[.,!?])/g).filter(token => token.trim());\n    const simulatedLogProbs = tokens.map(() => Math.log(0.8)); // Simulating 80% confidence\n    \n    return {\n      choices: [{\n        text,\n        logprobs: {\n          tokens,\n          token_logprobs: simulatedLogProbs,\n          top_logprobs: tokens.map(() => ({\n            [tokens[0]]: Math.log(0.8),\n            \"alternative1\": Math.log(0.1),\n            \"alternative2\": Math.log(0.05),\n            \"alternative3\": Math.log(0.05)\n          }))\n        }\n      }]\n    };\n  } catch (error) {\n    console.error('Error calling OpenAI API:', error.response?.data || error.message);\n    throw error;\n  }\n}; "],"mappings":"AAAA,OAAOA,KAAK,MAAM,OAAO;AAEzB,MAAMC,OAAO,GAAGC,OAAO,CAACC,GAAG,CAACC,wBAAwB;AACpD,MAAMC,OAAO,GAAG,4CAA4C;;AAE5D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMC,aAAa,GAAG,MAAAA,CAAOC,MAAM,EAAEC,SAAS,GAAG,EAAE,EAAEC,WAAW,GAAG,GAAG,EAAEC,QAAQ,GAAG,CAAC,KAAK;EAC9F,IAAI;IACF,MAAMC,QAAQ,GAAG,MAAMX,KAAK,CAACY,IAAI,CAC/BP,OAAO,EACP;MACEQ,KAAK,EAAE,eAAe;MACtBC,QAAQ,EAAE,CACR;QACEC,IAAI,EAAE,MAAM;QACZC,OAAO,EAAET;MACX,CAAC,CACF;MACDU,UAAU,EAAET,SAAS;MACrBC,WAAW;MACXC,QAAQ;MACRQ,MAAM,EAAE;IACV,CAAC,EACD;MACEC,OAAO,EAAE;QACP,cAAc,EAAE,kBAAkB;QAClC,eAAe,EAAE,UAAUlB,OAAO;MACpC;IACF,CACF,CAAC;;IAED;IACA,MAAMmB,IAAI,GAAGT,QAAQ,CAACU,IAAI,CAACC,OAAO,CAAC,CAAC,CAAC,CAACC,OAAO,CAACP,OAAO;;IAErD;IACA;IACA,MAAMQ,MAAM,GAAGJ,IAAI,CAACK,KAAK,CAAC,eAAe,CAAC,CAACC,MAAM,CAACC,KAAK,IAAIA,KAAK,CAACC,IAAI,CAAC,CAAC,CAAC;IACxE,MAAMC,iBAAiB,GAAGL,MAAM,CAACM,GAAG,CAAC,MAAMC,IAAI,CAACC,GAAG,CAAC,GAAG,CAAC,CAAC,CAAC,CAAC;;IAE3D,OAAO;MACLV,OAAO,EAAE,CAAC;QACRF,IAAI;QACJV,QAAQ,EAAE;UACRc,MAAM;UACNS,cAAc,EAAEJ,iBAAiB;UACjCK,YAAY,EAAEV,MAAM,CAACM,GAAG,CAAC,OAAO;YAC9B,CAACN,MAAM,CAAC,CAAC,CAAC,GAAGO,IAAI,CAACC,GAAG,CAAC,GAAG,CAAC;YAC1B,cAAc,EAAED,IAAI,CAACC,GAAG,CAAC,GAAG,CAAC;YAC7B,cAAc,EAAED,IAAI,CAACC,GAAG,CAAC,IAAI,CAAC;YAC9B,cAAc,EAAED,IAAI,CAACC,GAAG,CAAC,IAAI;UAC/B,CAAC,CAAC;QACJ;MACF,CAAC;IACH,CAAC;EACH,CAAC,CAAC,OAAOG,KAAK,EAAE;IAAA,IAAAC,eAAA;IACdC,OAAO,CAACF,KAAK,CAAC,2BAA2B,EAAE,EAAAC,eAAA,GAAAD,KAAK,CAACxB,QAAQ,cAAAyB,eAAA,uBAAdA,eAAA,CAAgBf,IAAI,KAAIc,KAAK,CAACZ,OAAO,CAAC;IACjF,MAAMY,KAAK;EACb;AACF,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}