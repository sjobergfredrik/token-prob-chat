{"ast":null,"code":"import axios from 'axios';\nconst API_KEY = process.env.REACT_APP_OPENAI_API_KEY;\nconst API_URL = 'https://api.openai.com/v1/completions'; // Note: using completions, not chat/completions\n\n/**\n * Sends a prompt to OpenAI API and retrieves the response with token probabilities\n * @param {string} prompt - The user's input prompt\n * @param {number} maxTokens - Maximum number of tokens to generate\n * @param {number} temperature - Controls randomness (0-1)\n * @param {number} logprobs - Number of most likely tokens to return\n * @returns {Promise} - The API response\n */\nexport const getCompletion = async (prompt, maxTokens = 50, temperature = 0.7, logprobs = 5) => {\n  try {\n    const response = await axios.post(API_URL, {\n      model: \"gpt-3.5-turbo-instruct\",\n      // This model supports logprobs\n      prompt,\n      max_tokens: maxTokens,\n      temperature,\n      logprobs,\n      top_p: 1,\n      frequency_penalty: 0,\n      presence_penalty: 0\n    }, {\n      headers: {\n        'Content-Type': 'application/json',\n        'Authorization': `Bearer ${API_KEY}`\n      }\n    });\n    return response.data;\n  } catch (error) {\n    var _error$response;\n    console.error('Error calling OpenAI API:', ((_error$response = error.response) === null || _error$response === void 0 ? void 0 : _error$response.data) || error.message);\n    throw error;\n  }\n};","map":{"version":3,"names":["axios","API_KEY","process","env","REACT_APP_OPENAI_API_KEY","API_URL","getCompletion","prompt","maxTokens","temperature","logprobs","response","post","model","max_tokens","top_p","frequency_penalty","presence_penalty","headers","data","error","_error$response","console","message"],"sources":["/Users/sjobergf/Documents/chatProbs/token-prob-chat/src/services/openaiService.js"],"sourcesContent":["import axios from 'axios';\n\nconst API_KEY = process.env.REACT_APP_OPENAI_API_KEY;\nconst API_URL = 'https://api.openai.com/v1/completions';  // Note: using completions, not chat/completions\n\n/**\n * Sends a prompt to OpenAI API and retrieves the response with token probabilities\n * @param {string} prompt - The user's input prompt\n * @param {number} maxTokens - Maximum number of tokens to generate\n * @param {number} temperature - Controls randomness (0-1)\n * @param {number} logprobs - Number of most likely tokens to return\n * @returns {Promise} - The API response\n */\nexport const getCompletion = async (prompt, maxTokens = 50, temperature = 0.7, logprobs = 5) => {\n  try {\n    const response = await axios.post(\n      API_URL,\n      {\n        model: \"gpt-3.5-turbo-instruct\",  // This model supports logprobs\n        prompt,\n        max_tokens: maxTokens,\n        temperature,\n        logprobs,\n        top_p: 1,\n        frequency_penalty: 0,\n        presence_penalty: 0\n      },\n      {\n        headers: {\n          'Content-Type': 'application/json',\n          'Authorization': `Bearer ${API_KEY}`\n        }\n      }\n    );\n    \n    return response.data;\n  } catch (error) {\n    console.error('Error calling OpenAI API:', error.response?.data || error.message);\n    throw error;\n  }\n}; "],"mappings":"AAAA,OAAOA,KAAK,MAAM,OAAO;AAEzB,MAAMC,OAAO,GAAGC,OAAO,CAACC,GAAG,CAACC,wBAAwB;AACpD,MAAMC,OAAO,GAAG,uCAAuC,CAAC,CAAE;;AAE1D;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAMC,aAAa,GAAG,MAAAA,CAAOC,MAAM,EAAEC,SAAS,GAAG,EAAE,EAAEC,WAAW,GAAG,GAAG,EAAEC,QAAQ,GAAG,CAAC,KAAK;EAC9F,IAAI;IACF,MAAMC,QAAQ,GAAG,MAAMX,KAAK,CAACY,IAAI,CAC/BP,OAAO,EACP;MACEQ,KAAK,EAAE,wBAAwB;MAAG;MAClCN,MAAM;MACNO,UAAU,EAAEN,SAAS;MACrBC,WAAW;MACXC,QAAQ;MACRK,KAAK,EAAE,CAAC;MACRC,iBAAiB,EAAE,CAAC;MACpBC,gBAAgB,EAAE;IACpB,CAAC,EACD;MACEC,OAAO,EAAE;QACP,cAAc,EAAE,kBAAkB;QAClC,eAAe,EAAE,UAAUjB,OAAO;MACpC;IACF,CACF,CAAC;IAED,OAAOU,QAAQ,CAACQ,IAAI;EACtB,CAAC,CAAC,OAAOC,KAAK,EAAE;IAAA,IAAAC,eAAA;IACdC,OAAO,CAACF,KAAK,CAAC,2BAA2B,EAAE,EAAAC,eAAA,GAAAD,KAAK,CAACT,QAAQ,cAAAU,eAAA,uBAAdA,eAAA,CAAgBF,IAAI,KAAIC,KAAK,CAACG,OAAO,CAAC;IACjF,MAAMH,KAAK;EACb;AACF,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}